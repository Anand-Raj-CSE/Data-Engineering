{"cells": [{"cell_type": "code", "execution_count": 1, "id": "786782c8-60a5-4bc8-bcdd-bf5990261ec4", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 2, "id": "f809355e-159c-4355-b6f4-7f0de7bd0554", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/20 06:49:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = SparkSession.builder \\\n.appName('Caching in Spark Tables').enableHiveSupport().getOrCreate()"}, {"cell_type": "code", "execution_count": 7, "id": "a3a7d233-3289-409e-9b21-018b75668d07", "metadata": {"tags": []}, "outputs": [], "source": "customer_schema = 'customer_id INT , name STRING , city STRING ,state STRING ,country STRING ,registartaion_date STRING , is_active BOOLEAN'"}, {"cell_type": "code", "execution_count": 5, "id": "3e2740d3-4fd1-4a51-b6b2-9faf96789099", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 6 items\n-rw-r--r--   2 root               hadoop       5488 2025-06-02 15:26 /data/customers_100.csv\n-rw-r--r--   2 geurecruitanandraj hadoop   10528211 2025-06-17 15:58 /data/customers_10mb.csv\n-rw-r--r--   2 geurecruitanandraj hadoop  168541068 2025-06-17 15:56 /data/customers_150mb.csv\n-rw-r--r--   2 geurecruitanandraj hadoop  343317147 2025-06-20 06:58 /data/customers_300mb.csv\n-rw-r--r--   2 geurecruitanandraj hadoop    8628599 2025-06-17 15:58 /data/orders_10.csv\n-rw-r--r--   2 geurecruitanandraj hadoop    7896035 2025-06-17 15:59 /data/shippings_10.csv\n"}], "source": "!hadoop fs -ls /data/"}, {"cell_type": "code", "execution_count": 8, "id": "f18f3e93-0479-4552-a7fc-03d6596229ef", "metadata": {"tags": []}, "outputs": [], "source": "cust_df = spark.read.schema(customer_schema).csv('/data/customers_300mb.csv')"}, {"cell_type": "code", "execution_count": null, "id": "3858a532-c424-4d7c-beb8-74385d4b30a0", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 9, "id": "5ee08608-03c2-4a92-9d5d-da3f28a1be41", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n25/06/20 07:03:43 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `spark_catalog`.`default`.`customers_500mb` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n25/06/20 07:03:43 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"}], "source": "cust_df.write.format('csv').saveAsTable('default.customers_500mb')"}, {"cell_type": "code", "execution_count": 10, "id": "69c201d5-875e-405d-963b-5a0316fe6b21", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------------+---------+-------+\n|          col_name|data_type|comment|\n+------------------+---------+-------+\n|       customer_id|      int|   NULL|\n|              name|   string|   NULL|\n|              city|   string|   NULL|\n|             state|   string|   NULL|\n|           country|   string|   NULL|\n|registartaion_date|   string|   NULL|\n|         is_active|  boolean|   NULL|\n+------------------+---------+-------+\n\n"}], "source": "spark.sql('DESCRIBE default.customers_500mb').show()"}, {"cell_type": "code", "execution_count": 11, "id": "e3503094-b482-4159-b591-8715361ae580", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------+---------------------------------------------------------+-------+\n|col_name                    |data_type                                                |comment|\n+----------------------------+---------------------------------------------------------+-------+\n|customer_id                 |int                                                      |NULL   |\n|name                        |string                                                   |NULL   |\n|city                        |string                                                   |NULL   |\n|state                       |string                                                   |NULL   |\n|country                     |string                                                   |NULL   |\n|registartaion_date          |string                                                   |NULL   |\n|is_active                   |boolean                                                  |NULL   |\n|                            |                                                         |       |\n|# Detailed Table Information|                                                         |       |\n|Catalog                     |spark_catalog                                            |       |\n|Database                    |default                                                  |       |\n|Table                       |customers_500mb                                          |       |\n|Owner                       |root                                                     |       |\n|Created Time                |Fri Jun 20 07:03:44 UTC 2025                             |       |\n|Last Access                 |UNKNOWN                                                  |       |\n|Created By                  |Spark 3.5.3                                              |       |\n|Type                        |MANAGED                                                  |       |\n|Provider                    |csv                                                      |       |\n|Statistics                  |343317127 bytes                                          |       |\n|Location                    |hdfs://cluster-2271-m/user/hive/warehouse/customers_500mb|       |\n+----------------------------+---------------------------------------------------------+-------+\nonly showing top 20 rows\n\n"}], "source": "spark.sql('DESCRIBE EXTENDED default.customers_500mb').show(truncate=False)"}, {"cell_type": "code", "execution_count": 13, "id": "77ee4f57-d3dd-4583-8fe5-320c2bc16698", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 4 items\n-rw-r--r--   2 root hadoop          0 2025-06-20 07:03 /user/hive/warehouse/customers_500mb/_SUCCESS\n-rw-r--r--   2 root hadoop    128.0 M 2025-06-20 07:03 /user/hive/warehouse/customers_500mb/part-00000-dbbbbe46-7ea3-4c44-a12d-b154efc74e96-c000.csv\n-rw-r--r--   2 root hadoop    128.0 M 2025-06-20 07:03 /user/hive/warehouse/customers_500mb/part-00001-dbbbbe46-7ea3-4c44-a12d-b154efc74e96-c000.csv\n-rw-r--r--   2 root hadoop     71.4 M 2025-06-20 07:03 /user/hive/warehouse/customers_500mb/part-00002-dbbbbe46-7ea3-4c44-a12d-b154efc74e96-c000.csv\n"}], "source": "!hadoop fs -ls -h /user/hive/warehouse/customers_500mb"}, {"cell_type": "code", "execution_count": 15, "id": "5eb72591-9fef-42dd-90e5-78c44a638295", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+------+-----------+-------+------------------+---------+\n|customer_id|      name|  city|      state|country|registartaion_date|is_active|\n+-----------+----------+------+-----------+-------+------------------+---------+\n|       NULL|      name|  city|      state|country| registration_date|     NULL|\n|          0|Customer_0|  Pune|Maharashtra|  India|        2023-01-19|     true|\n|          1|Customer_1|  Pune|West Bengal|  India|        2023-08-10|     true|\n|          2|Customer_2| Delhi|Maharashtra|  India|        2023-08-05|     true|\n|          3|Customer_3|Mumbai|  Telangana|  India|        2023-06-04|     true|\n+-----------+----------+------+-----------+-------+------------------+---------+\n\n"}], "source": "spark.sql('SELECT * FROM customers_500mb limit 5').show()"}, {"cell_type": "code", "execution_count": 16, "id": "91c3aaec-a890-48b9-862f-121db1de4af9", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 2:=======================================>                   (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n| 5286939|\n+--------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql('Select count(*) from customers_500mb').show()"}, {"cell_type": "markdown", "id": "8642693c-bcdd-4d2b-8284-f66ef210239d", "metadata": {}, "source": "### Caching in spark tables, caching is eager , as we hit caching command it would start to cache data, which could be seen in storage."}, {"cell_type": "code", "execution_count": 17, "id": "1dbde32a-fb4d-4ca7-8767-b3dd1eea1036", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql('CACHE TABLE default.customers_500mb')"}, {"cell_type": "code", "execution_count": 19, "id": "88ab5081-35ab-4337-9400-d8a66fc3b27c", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+-------+-----------+-------+------------------+---------+\n|customer_id|      name|   city|      state|country|registartaion_date|is_active|\n+-----------+----------+-------+-----------+-------+------------------+---------+\n|       NULL|      name|   city|      state|country| registration_date|     NULL|\n|          0|Customer_0|   Pune|Maharashtra|  India|        2023-01-19|     true|\n|          1|Customer_1|   Pune|West Bengal|  India|        2023-08-10|     true|\n|          2|Customer_2|  Delhi|Maharashtra|  India|        2023-08-05|     true|\n|          3|Customer_3| Mumbai|  Telangana|  India|        2023-06-04|     true|\n|          4|Customer_4|  Delhi|  Karnataka|  India|        2023-03-15|    false|\n|          5|Customer_5|Kolkata|West Bengal|  India|        2023-08-19|     true|\n|          6|Customer_6|Kolkata| Tamil Nadu|  India|        2023-04-21|    false|\n|          7|Customer_7| Mumbai|  Telangana|  India|        2023-05-23|     true|\n|          8|Customer_8|   Pune| Tamil Nadu|  India|        2023-07-17|     true|\n+-----------+----------+-------+-----------+-------+------------------+---------+\n\n"}], "source": "spark.sql('SELECT * FROM customers_500mb limit 10').show()"}, {"cell_type": "code", "execution_count": 20, "id": "98bb6d3a-42e9-4ce1-844a-c504989f6515", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n| 5286939|\n+--------+\n\n"}], "source": "spark.sql('Select count(*) from customers_500mb').show()"}, {"cell_type": "code", "execution_count": 21, "id": "94ea7e5a-d134-4e21-9f2c-fa190a2a50cb", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 13:======================================>                   (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+--------+\n|     city|count(1)|\n+---------+--------+\n|    Delhi|  661025|\n|  Kolkata|  660174|\n|Hyderabad|  662281|\n|     city|       1|\n|Bangalore|  661013|\n|Ahmedabad|  660218|\n|  Chennai|  660249|\n|   Mumbai|  661241|\n|     Pune|  660737|\n+---------+--------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql('SELECT city , count(*) from customers_500mb group by city').show()"}, {"cell_type": "markdown", "id": "d5b29028-f7cf-4e5a-9cd3-8e4f2d72c42c", "metadata": {}, "source": "#### These are much faster as the data is being read from cache , insted of going through tables.\n## Uncaching the table"}, {"cell_type": "code", "execution_count": 22, "id": "cb7916c7-62b0-4cc6-88c8-8bb8f5614968", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "DataFrame[]"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql('UNCACHE TABLE customers_500mb')"}, {"cell_type": "code", "execution_count": 23, "id": "3c7e433f-0342-4e49-98ad-d03a1ecde881", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "DataFrame[]"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "# Lazy cahing / uncahing\nspark.sql('CACHE LAZY TABLE customers_500mb')"}, {"cell_type": "code", "execution_count": 24, "id": "cddd9aad-4ecd-4f5b-bff3-0253a191d72c", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 17:======================================>                   (2 + 1) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+--------+\n|     city|count(1)|\n+---------+--------+\n|    Delhi|  661025|\n|  Kolkata|  660174|\n|Hyderabad|  662281|\n|     city|       1|\n|Bangalore|  661013|\n|Ahmedabad|  660218|\n|  Chennai|  660249|\n|   Mumbai|  661241|\n|     Pune|  660737|\n+---------+--------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql('SELECT city , count(*) from customers_500mb group by city').show()"}, {"cell_type": "code", "execution_count": 26, "id": "c95b03f7-d149-4035-b3ae-2750fc3644fe", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+---------------+-----------+\n|namespace|      tableName|isTemporary|\n+---------+---------------+-----------+\n|  default|customers_500mb|      false|\n+---------+---------------+-----------+\n\n"}], "source": "spark.sql('show tables').show()"}, {"cell_type": "markdown", "id": "6e57f13d-3630-4c66-8f0a-eaca9bfdf2b5", "metadata": {"tags": []}, "source": "## All cache removal , no cached data"}, {"cell_type": "code", "execution_count": 28, "id": "52d4dde6-f67e-490a-ad7b-65b4a18482a8", "metadata": {"tags": []}, "outputs": [], "source": "spark.catalog.clearCache()"}, {"cell_type": "code", "execution_count": null, "id": "6294cb4e-5d7a-44bd-b7c1-96b76eb9f7ac", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}