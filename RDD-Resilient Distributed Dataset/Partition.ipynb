{"cells": [{"cell_type": "code", "execution_count": null, "id": "df6cd5ed-8625-44b3-80e4-f659181eba6a", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 1, "id": "ebb55a3c-5af8-4857-950b-0e62b0177cf8", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/05/16 12:57:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = SparkSession.builder\\\n.appName(\"partition\")\\\n.master('yarn')\\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "767b64ed-a2f4-4268-a148-c25d572d61c5", "metadata": {"tags": []}, "outputs": [], "source": "data = [\"Goku Vegata Gohan\",\n       \"Goku Frieza Goku\",\n       \"Vegata Goku Frieza Gohan\",\n       \"Gohan Frieza Goku\" ]"}, {"cell_type": "code", "execution_count": 3, "id": "580b569e-acff-45f4-aeb0-36dbc978b009", "metadata": {"tags": []}, "outputs": [], "source": "local_rdd = spark.sparkContext.parallelize(data)"}, {"cell_type": "code", "execution_count": 4, "id": "26965fd4-4bbc-4395-92e6-497f4cfa0093", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 6 items\n-rw-r--r--   2 geurecruitanandraj hadoop      1.0 M 2025-05-14 10:17 /tmp/customers.csv\n-rw-r--r--   2 geurecruitanandraj hadoop     10.0 M 2025-05-14 10:27 /tmp/customers_10mb.csv\n-rw-r--r--   2 geurecruitanandraj hadoop    160.7 M 2025-05-14 12:27 /tmp/customers_150mb.csv\ndrwxrwxrwt   - hdfs               hadoop          0 2025-04-26 14:44 /tmp/hadoop-yarn\ndrwx-wx-wx   - hive               hadoop          0 2025-04-26 14:44 /tmp/hive\n-rw-r--r--   2 root               hadoop         78 2025-05-01 14:03 /tmp/inputhdfsbdz.txt\n"}], "source": "# get hadoop files from hadoop file system\n!hadoop fs -ls -h /tmp/"}, {"cell_type": "code", "execution_count": 8, "id": "4b73e8bc-ea6b-4515-af0c-aaaace182b71", "metadata": {"tags": []}, "outputs": [], "source": "local_rdd = spark.sparkContext.parallelize(data)\nbig_hdfs_path = '/tmp/customers_150mb.csv'\nbig_rdd_data_from_hdfs = spark.sparkContext.textFile(big_hdfs_path)"}, {"cell_type": "code", "execution_count": 10, "id": "06066be4-c0dc-42a2-9876-de8d70cf228c", "metadata": {"tags": []}, "outputs": [], "source": "small_hdfs_data = '/tmp/customers.csv'\nsmall_rdd_from_hdfs = spark.sparkContext.textFile(small_hdfs_data)"}, {"cell_type": "code", "execution_count": 15, "id": "459553b9-d8e7-405b-8e73-4c548a6e8ed6", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "2"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "# Get the number of partitions \nbig_rdd_data_from_hdfs.getNumPartitions() #- 128MB each block size"}, {"cell_type": "code", "execution_count": 16, "id": "4674bae0-d508-42af-82cf-241147e70054", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "2"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "small_rdd_from_hdfs.getNumPartitions()"}, {"cell_type": "code", "execution_count": 18, "id": "bcf9edd5-1a9e-44f7-b2d0-2850be25d725", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Maximum partition Bytes: 134217728b\n"}], "source": "print(f\"Maximum partition Bytes: {spark.conf.get('spark.sql.files.maxPartitionBytes')}\")"}, {"cell_type": "code", "execution_count": 19, "id": "413ebb7e-5c6f-4dde-83c0-e9ae1d88a6da", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "2"}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sparkContext.defaultParallelism"}, {"cell_type": "code", "execution_count": null, "id": "508e54e8-6817-4600-9492-2aba9972a37d", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}