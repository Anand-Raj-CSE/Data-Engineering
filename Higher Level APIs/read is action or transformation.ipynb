{"cells": [{"cell_type": "code", "execution_count": 1, "id": "da2e8c92-772f-4898-9ea8-567850451462", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 2, "id": "6d746bb3-2d7b-410c-9b59-7eb84965d027", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/07 06:40:37 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = SparkSession.builder \\\n.appName('Read - Action or Transformation')\\\n.master('Yarn').getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "id": "f2ee23fd-102b-461f-9370-4baafef16266", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.read \\\n.format('csv') \\\n.option('header','true')\\\n.option('inferSchema','true') \\\n.load('/data/customers_100.csv')"}, {"cell_type": "markdown", "id": "f2e76aa5-59ea-4aaf-bfcf-5c47002f9462", "metadata": {}, "source": "### When inferSchema is false or not selected spark reads only a single partition out of many created in case of header is true just to get the header , when inferschema is true then whole data is read from all partitions created."}, {"cell_type": "code", "execution_count": 5, "id": "283c669c-a623-4742-b26c-756ee6e57034", "metadata": {"tags": []}, "outputs": [], "source": "# making our own schema\nfrom pyspark.sql.types import *\nschema = StructType([\n    StructField(\"customer_id\",IntegerType(), True),\n    StructField(\"name\",StringType(), True),\n    StructField(\"city\",StringType(), True),\n    StructField(\"state\",StringType(), True),\n    StructField(\"country\",StringType(), True),\n    StructField(\"registartion_date\",StringType(), True),\n    StructField(\"is_active\",BooleanType(), True),\n])"}, {"cell_type": "code", "execution_count": 6, "id": "a5544d43-905d-4102-9156-9f0ed4549904", "metadata": {"tags": []}, "outputs": [], "source": "df = spark.read\\\n.format('csv').option('header','true')\\\n.schema(schema).load('/data/customers_100.csv')"}, {"cell_type": "markdown", "id": "92c71ee9-82bc-4c2e-b9d7-1317ac396b06", "metadata": {}, "source": "### No Data is read in case when we provide our our own schema details , i.e. Lazy Evaluation."}, {"cell_type": "code", "execution_count": 7, "id": "5c95c668-6c74-4efe-9c73-408edeafb64e", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "99"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "df.count()"}, {"cell_type": "code", "execution_count": null, "id": "dd24dc44-43b3-424f-b078-313131606efc", "metadata": {}, "outputs": [], "source": "spark.stop()"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}