{"cells": [{"cell_type": "code", "execution_count": 2, "id": "ef62cde5-6aec-40eb-8016-314af5b78faf", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 4, "id": "60812a38-5c41-4a82-b4e5-e2dfd1f5490f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/01 16:33:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = SparkSession.builder\\\n.appName('Higher level APIs').getOrCreate()"}, {"cell_type": "code", "execution_count": 5, "id": "d7a3466b-b0de-4b3d-a427-a84997270a0e", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.read.format('csv')\\\n.option('header','true')\\\n.option('inferschema','true')\\\n.load('/tmp/customers.csv')"}, {"cell_type": "code", "execution_count": 6, "id": "302f600d-38c7-4dce-9b2d-f1b7d3eaafd3", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+-----------+---------+-----------+-------+-----------------+---------+\n|customer_id|       name|     city|      state|country|registration_date|is_active|\n+-----------+-----------+---------+-----------+-------+-----------------+---------+\n|          0| Customer_0|     Pune|Maharashtra|  India|       2023-06-29|    false|\n|          1| Customer_1|Bangalore| Tamil Nadu|  India|       2023-12-07|     true|\n|          2| Customer_2|Hyderabad|    Gujarat|  India|       2023-10-27|     true|\n|          3| Customer_3|Bangalore|  Karnataka|  India|       2023-10-17|    false|\n|          4| Customer_4|Ahmedabad|  Karnataka|  India|       2023-03-14|    false|\n|          5| Customer_5|Hyderabad|  Karnataka|  India|       2023-07-28|    false|\n|          6| Customer_6|     Pune|      Delhi|  India|       2023-08-29|    false|\n|          7| Customer_7|Ahmedabad|West Bengal|  India|       2023-12-28|     true|\n|          8| Customer_8|     Pune|  Karnataka|  India|       2023-06-22|     true|\n|          9| Customer_9|   Mumbai|  Telangana|  India|       2023-01-05|     true|\n|         10|Customer_10|     Pune|    Gujarat|  India|       2023-08-05|     true|\n|         11|Customer_11|    Delhi|West Bengal|  India|       2023-08-02|    false|\n|         12|Customer_12|  Chennai|    Gujarat|  India|       2023-11-21|    false|\n|         13|Customer_13|  Chennai|  Karnataka|  India|       2023-11-06|     true|\n|         14|Customer_14|Hyderabad| Tamil Nadu|  India|       2023-02-07|    false|\n|         15|Customer_15|   Mumbai|    Gujarat|  India|       2023-03-02|     true|\n|         16|Customer_16|  Chennai|  Karnataka|  India|       2023-04-05|    false|\n|         17|Customer_17|Hyderabad|West Bengal|  India|       2023-08-21|    false|\n|         18|Customer_18|     Pune|      Delhi|  India|       2023-10-04|     true|\n|         19|Customer_19|  Kolkata|    Gujarat|  India|       2023-02-05|     true|\n+-----------+-----------+---------+-----------+-------+-----------------+---------+\nonly showing top 20 rows\n\nNone\n"}], "source": "print(df.show())"}, {"cell_type": "code", "execution_count": 7, "id": "4617851b-60d4-4e75-ba5e-e5e512b01a91", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- country: string (nullable = true)\n |-- registration_date: date (nullable = true)\n |-- is_active: boolean (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 9, "id": "a4d93189-5bb9-4a10-b537-3e754233c7b3", "metadata": {"tags": []}, "outputs": [], "source": "df.createOrReplaceTempView('customers')"}, {"cell_type": "code", "execution_count": 10, "id": "61cee3b2-a2e8-4a5c-a782-604328cd0dcd", "metadata": {"tags": []}, "outputs": [], "source": "result = spark.sql('Select city , count(*) from customers group by city')"}, {"cell_type": "code", "execution_count": 11, "id": "855fe149-e6c4-4a44-9c76-e8aefb5eef86", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+--------+\n|     city|count(1)|\n+---------+--------+\n|    Delhi|    2200|\n|  Kolkata|    2223|\n|Hyderabad|    2242|\n|Bangalore|    2211|\n|Ahmedabad|    2198|\n|  Chennai|    2194|\n|   Mumbai|    2142|\n|     Pune|    2243|\n+---------+--------+\n\n"}], "source": "result.show()"}, {"cell_type": "code", "execution_count": null, "id": "e5ce376d-a068-46ac-b215-21622353ccd9", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}