{"cells": [{"cell_type": "code", "execution_count": 1, "id": "4aaa3ecb-c882-4850-9664-3b54bcb24568", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 2, "id": "649b1bea-993a-4519-9aaf-646bf6757bf1", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/10 16:05:04 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark = SparkSession.builder \\\n.appName('DataTypes in Pyspark').getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "16b27cae-62c9-4ef0-9a57-a47e4657ed92", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---+--------------+---------+----------+-------+---------+\n| id|          name|     city|      date| amount|is_active|\n+---+--------------+---------+----------+-------+---------+\n|  1|      John Doe|Bangalore|2023-01-15|152.725|     true|\n|  2|    Jane Smith|    Delhi|2024-01-15|172.725|     true|\n|  3|     John Depp|   Mumbai|2023-06-15|122.725|     true|\n|  4|Dharambeer Das|  Kolkata|2023-07-15|132.725|     true|\n|  5|   Nishtha Pal|   Ranchi|2023-01-17|158.725|     true|\n|  6|Bharathi Vidya|  Chennai|2023-04-25|142.725|     true|\n|  7|    Yogesh Raj|   kocchi|2023-05-25|157.725|     true|\n|  8|Soujanya Bhatt|     Pune|2023-09-25|158.725|     true|\n|  9| Sourabh Joshi| Hyderbad|2024-11-15|159.725|     true|\n+---+--------------+---------+----------+-------+---------+\n\n"}], "source": "data = [\n    (1,\"John Doe\",\"Bangalore\",\"2023-01-15\",\"152.725\",True),\n    (2,\"Jane Smith\",\"Delhi\",\"2024-01-15\",\"172.725\",True),\n    (3,\"John Depp\",\"Mumbai\",\"2023-06-15\",\"122.725\",True),\n    (4,\"Dharambeer Das\",\"Kolkata\",\"2023-07-15\",\"132.725\",True),\n    (5,\"Nishtha Pal\",\"Ranchi\",\"2023-01-17\",\"158.725\",True),\n    (6,\"Bharathi Vidya\",\"Chennai\",\"2023-04-25\",\"142.725\",True),\n    (7,\"Yogesh Raj\",\"kocchi\",\"2023-05-25\",\"157.725\",True),\n    (8,\"Soujanya Bhatt\",\"Pune\",\"2023-09-25\",\"158.725\",True),\n    (9,\"Sourabh Joshi\",\"Hyderbad\",\"2024-11-15\",\"159.725\",True),\n]\n\ncolumns = [\"id\",\"name\",\"city\",\"date\",\"amount\",\"is_active\"]\n\ndf = spark.createDataFrame(data,schema=columns)\n\ndf.show()"}, {"cell_type": "code", "execution_count": 4, "id": "7e7b8977-89e5-43d5-b1d2-3c760b5de08d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- date: string (nullable = true)\n |-- amount: string (nullable = true)\n |-- is_active: boolean (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 5, "id": "2d61f60f-4673-4d86-9923-f5d469353d37", "metadata": {"tags": []}, "outputs": [], "source": "# How to handling integer column\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import col\n\ndf = df.withColumn('id' , col('id').cast(IntegerType()))"}, {"cell_type": "code", "execution_count": 6, "id": "da506539-7c98-48b5-9e73-fd9b29a1f20d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+--------------+---------+----------+-------+---------+\n| id|          name|     city|      date| amount|is_active|\n+---+--------------+---------+----------+-------+---------+\n|  1|      John Doe|Bangalore|2023-01-15|152.725|     true|\n|  2|    Jane Smith|    Delhi|2024-01-15|172.725|     true|\n|  3|     John Depp|   Mumbai|2023-06-15|122.725|     true|\n|  4|Dharambeer Das|  Kolkata|2023-07-15|132.725|     true|\n|  5|   Nishtha Pal|   Ranchi|2023-01-17|158.725|     true|\n|  6|Bharathi Vidya|  Chennai|2023-04-25|142.725|     true|\n|  7|    Yogesh Raj|   kocchi|2023-05-25|157.725|     true|\n|  8|Soujanya Bhatt|     Pune|2023-09-25|158.725|     true|\n|  9| Sourabh Joshi| Hyderbad|2024-11-15|159.725|     true|\n+---+--------------+---------+----------+-------+---------+\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 7, "id": "6f7564af-8dbf-4463-8dd6-ad7c3d7bec40", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- date: string (nullable = true)\n |-- amount: string (nullable = true)\n |-- is_active: boolean (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 8, "id": "a7e9e6ea-b89f-43bf-85ba-1a348b5e375b", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+--------------+---------+----------+-------+---------+--------------+\n| id|          name|     city|      date| amount|is_active|    name_upper|\n+---+--------------+---------+----------+-------+---------+--------------+\n|  1|      John Doe|Bangalore|2023-01-15|152.725|     true|      JOHN DOE|\n|  2|    Jane Smith|    Delhi|2024-01-15|172.725|     true|    JANE SMITH|\n|  3|     John Depp|   Mumbai|2023-06-15|122.725|     true|     JOHN DEPP|\n|  4|Dharambeer Das|  Kolkata|2023-07-15|132.725|     true|DHARAMBEER DAS|\n|  5|   Nishtha Pal|   Ranchi|2023-01-17|158.725|     true|   NISHTHA PAL|\n|  6|Bharathi Vidya|  Chennai|2023-04-25|142.725|     true|BHARATHI VIDYA|\n|  7|    Yogesh Raj|   kocchi|2023-05-25|157.725|     true|    YOGESH RAJ|\n|  8|Soujanya Bhatt|     Pune|2023-09-25|158.725|     true|SOUJANYA BHATT|\n|  9| Sourabh Joshi| Hyderbad|2024-11-15|159.725|     true| SOURABH JOSHI|\n+---+--------------+---------+----------+-------+---------+--------------+\n\n"}], "source": "# String COlumns\nfrom pyspark.sql.functions import *\ndf = df.withColumn('name_upper',upper(df.name))\ndf.show()"}, {"cell_type": "code", "execution_count": 9, "id": "7a590c62-2d58-47c6-b06e-e1e8d376dddb", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+--------+---------+----------+-------+---------+----------+\n| id|    name|     city|      date| amount|is_active|name_upper|\n+---+--------+---------+----------+-------+---------+----------+\n|  1|John Doe|Bangalore|2023-01-15|152.725|     true|  JOHN DOE|\n+---+--------+---------+----------+-------+---------+----------+\n\n"}], "source": "df.filter(df.city.startswith('B')).show()"}, {"cell_type": "code", "execution_count": 10, "id": "35f69e69-b9d0-4532-9082-9da904d60bc4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- date: string (nullable = true)\n |-- amount: float (nullable = true)\n |-- is_active: boolean (nullable = true)\n |-- name_upper: string (nullable = true)\n\n+---+--------------+---------+----------+-------+---------+--------------+\n| id|          name|     city|      date| amount|is_active|    name_upper|\n+---+--------------+---------+----------+-------+---------+--------------+\n|  1|      John Doe|Bangalore|2023-01-15|152.725|     true|      JOHN DOE|\n|  2|    Jane Smith|    Delhi|2024-01-15|172.725|     true|    JANE SMITH|\n|  3|     John Depp|   Mumbai|2023-06-15|122.725|     true|     JOHN DEPP|\n|  4|Dharambeer Das|  Kolkata|2023-07-15|132.725|     true|DHARAMBEER DAS|\n|  5|   Nishtha Pal|   Ranchi|2023-01-17|158.725|     true|   NISHTHA PAL|\n|  6|Bharathi Vidya|  Chennai|2023-04-25|142.725|     true|BHARATHI VIDYA|\n|  7|    Yogesh Raj|   kocchi|2023-05-25|157.725|     true|    YOGESH RAJ|\n|  8|Soujanya Bhatt|     Pune|2023-09-25|158.725|     true|SOUJANYA BHATT|\n|  9| Sourabh Joshi| Hyderbad|2024-11-15|159.725|     true| SOURABH JOSHI|\n+---+--------------+---------+----------+-------+---------+--------------+\n\n"}], "source": "# handle float column\ndf = df.withColumn('amount',col('amount').cast('float'))\ndf.printSchema()\ndf.show()"}, {"cell_type": "markdown", "id": "42d00ea0-0378-41e5-aedc-22f5e60b3e48", "metadata": {}, "source": "### Handling Date datatypes"}, {"cell_type": "code", "execution_count": 19, "id": "97503f5a-636d-45a1-905c-bb8ab1804b05", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+----------+----------+----------+-------------------+\n| id|  date_iso|  date_dmy|  date_mdy|          timestamp|\n+---+----------+----------+----------+-------------------+\n|  1|2025-06-10|10/06/2025|06/10/2025|2025-06-10 15:42:17|\n|  2|2025-07-15|15/07/2025|07/15/2025|2025-07-15 08:30:00|\n|  3|2025-08-20|20/08/2025|08/20/2025|2025-08-20 22:11:45|\n|  4|2025-13-40|40/13/2025|13/40/2025|2025-13-40 13:05:30|\n|  5|2025-02-30|30/02/2025|02/30/2025|2025-02-30 19:55:10|\n+---+----------+----------+----------+-------------------+\n\n"}], "source": "data = [\n    (1, \"2025-06-10\", \"10/06/2025\", \"06/10/2025\", \"2025-06-10 15:42:17\"),\n    (2, \"2025-07-15\", \"15/07/2025\", \"07/15/2025\", \"2025-07-15 08:30:00\"),\n    (3, \"2025-08-20\", \"20/08/2025\", \"08/20/2025\", \"2025-08-20 22:11:45\"),\n    (4, \"2025-13-40\", \"40/13/2025\", \"13/40/2025\", \"2025-13-40 13:05:30\"),  # Invalid date\n    (5, \"2025-02-30\", \"30/02/2025\", \"02/30/2025\", \"2025-02-30 19:55:10\")   # Invalid date\n]\n\ncolumns = [\"id\",\"date_iso\",\"date_dmy\",\"date_mdy\",\"timestamp\"]\n\ndf = spark.createDataFrame(data,schema=columns)\n\ndf.show()"}, {"cell_type": "code", "execution_count": 20, "id": "fa083596-ab43-46cc-a13c-f331355eea9e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: long (nullable = true)\n |-- date_iso: string (nullable = true)\n |-- date_dmy: string (nullable = true)\n |-- date_mdy: string (nullable = true)\n |-- timestamp: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 21, "id": "48076ffe-62d8-4467-8a53-7931e6ddda56", "metadata": {"tags": []}, "outputs": [], "source": "df = df\\\n    .withColumn('parsed_date_iso', to_date(df.date_iso,'yyyy-mm-dd')) \\\n    .withColumn('parsed_date_dmy', to_date(df.date_dmy,'dd/mm/yyyy')) \\\n    .withColumn('parsed_date_mdy', to_date(df.date_mdy,'mm/dd/yyyy'))"}, {"cell_type": "code", "execution_count": 22, "id": "8452fcd4-f838-4c93-9d24-116245eafc3d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+----------+----------+----------+-------------------+---------------+---------------+---------------+\n| id|  date_iso|  date_dmy|  date_mdy|          timestamp|parsed_date_iso|parsed_date_dmy|parsed_date_mdy|\n+---+----------+----------+----------+-------------------+---------------+---------------+---------------+\n|  1|2025-06-10|10/06/2025|06/10/2025|2025-06-10 15:42:17|     2025-01-10|     2025-01-10|     2025-01-10|\n|  2|2025-07-15|15/07/2025|07/15/2025|2025-07-15 08:30:00|     2025-01-15|     2025-01-15|     2025-01-15|\n|  3|2025-08-20|20/08/2025|08/20/2025|2025-08-20 22:11:45|     2025-01-20|     2025-01-20|     2025-01-20|\n|  4|2025-13-40|40/13/2025|13/40/2025|2025-13-40 13:05:30|           NULL|           NULL|           NULL|\n|  5|2025-02-30|30/02/2025|02/30/2025|2025-02-30 19:55:10|     2025-01-30|     2025-01-30|     2025-01-30|\n+---+----------+----------+----------+-------------------+---------------+---------------+---------------+\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 24, "id": "5bff5d04-0d65-494b-9258-0d9ba3556ac6", "metadata": {"tags": []}, "outputs": [], "source": "# Handling timestamp\nfrom pyspark.sql.functions import to_timestamp,year,dayofmonth , hour , minute"}, {"cell_type": "code", "execution_count": 25, "id": "02870fdf-c291-4cec-8934-b460cc768657", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n| id|  date_iso|  date_dmy|  date_mdy|          timestamp|parsed_date_iso|parsed_date_dmy|parsed_date_mdy|   parsed_timestamp|\n+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n|  1|2025-06-10|10/06/2025|06/10/2025|2025-06-10 15:42:17|     2025-01-10|     2025-01-10|     2025-01-10|2025-06-10 15:42:17|\n|  2|2025-07-15|15/07/2025|07/15/2025|2025-07-15 08:30:00|     2025-01-15|     2025-01-15|     2025-01-15|2025-07-15 08:30:00|\n|  3|2025-08-20|20/08/2025|08/20/2025|2025-08-20 22:11:45|     2025-01-20|     2025-01-20|     2025-01-20|2025-08-20 22:11:45|\n|  4|2025-13-40|40/13/2025|13/40/2025|2025-13-40 13:05:30|           NULL|           NULL|           NULL|               NULL|\n|  5|2025-02-30|30/02/2025|02/30/2025|2025-02-30 19:55:10|     2025-01-30|     2025-01-30|     2025-01-30|               NULL|\n+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n\nroot\n |-- id: long (nullable = true)\n |-- date_iso: string (nullable = true)\n |-- date_dmy: string (nullable = true)\n |-- date_mdy: string (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- parsed_date_iso: date (nullable = true)\n |-- parsed_date_dmy: date (nullable = true)\n |-- parsed_date_mdy: date (nullable = true)\n |-- parsed_timestamp: timestamp (nullable = true)\n\n"}], "source": "df = df.withColumn('parsed_timestamp',to_timestamp(df.timestamp))\ndf.show()\ndf.printSchema()"}, {"cell_type": "code", "execution_count": 27, "id": "e3aac956-06d5-4df6-8dbe-76e66c0751ee", "metadata": {"tags": []}, "outputs": [], "source": "df = df.withColumn('year',year(df.parsed_timestamp))\\\n.withColumn('month',dayofmonth(df.parsed_timestamp))\\\n.withColumn('day',day(df.parsed_timestamp))\\\n.withColumn('hour',hour(df.parsed_timestamp))\\\n.withColumn('minute',minute(df.parsed_timestamp))"}, {"cell_type": "code", "execution_count": 28, "id": "7769e28f-bb9a-4526-9794-4b63a11f3b12", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+----+-----+----+----+------+\n| id|  date_iso|  date_dmy|  date_mdy|          timestamp|parsed_date_iso|parsed_date_dmy|parsed_date_mdy|   parsed_timestamp|year|month| day|hour|minute|\n+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+----+-----+----+----+------+\n|  1|2025-06-10|10/06/2025|06/10/2025|2025-06-10 15:42:17|     2025-01-10|     2025-01-10|     2025-01-10|2025-06-10 15:42:17|2025|   10|  10|  15|    42|\n|  2|2025-07-15|15/07/2025|07/15/2025|2025-07-15 08:30:00|     2025-01-15|     2025-01-15|     2025-01-15|2025-07-15 08:30:00|2025|   15|  15|   8|    30|\n|  3|2025-08-20|20/08/2025|08/20/2025|2025-08-20 22:11:45|     2025-01-20|     2025-01-20|     2025-01-20|2025-08-20 22:11:45|2025|   20|  20|  22|    11|\n|  4|2025-13-40|40/13/2025|13/40/2025|2025-13-40 13:05:30|           NULL|           NULL|           NULL|               NULL|NULL| NULL|NULL|NULL|  NULL|\n|  5|2025-02-30|30/02/2025|02/30/2025|2025-02-30 19:55:10|     2025-01-30|     2025-01-30|     2025-01-30|               NULL|NULL| NULL|NULL|NULL|  NULL|\n+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+----+-----+----+----+------+\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 30, "id": "461a0104-c7b3-43ae-960e-e9dd97cfb90d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+---------------+---------------+\n|parsed_date_dmy|parsed_date_iso|days_difference|\n+---------------+---------------+---------------+\n|     2025-01-10|     2025-01-10|              0|\n|     2025-01-15|     2025-01-15|              0|\n|     2025-01-20|     2025-01-20|              0|\n|           NULL|           NULL|           NULL|\n|     2025-01-30|     2025-01-30|              0|\n+---------------+---------------+---------------+\n\n"}], "source": "from pyspark.sql.functions import datediff\ndf = df.withColumn('days_difference', datediff(df.parsed_date_dmy,df.parsed_date_iso))\n\ndf.select('parsed_date_dmy','parsed_date_iso','days_difference').show()"}, {"cell_type": "code", "execution_count": 31, "id": "4c7b6800-359d-410c-908e-5f8ab827a875", "metadata": {"tags": []}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "d129b763-4fad-43d8-98af-14fc7a9f3f99", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}